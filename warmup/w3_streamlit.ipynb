{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dattnguyen1991/aio_warmup_draft/blob/main/warmup/w3_streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znxPoNGjvj-D"
      },
      "source": [
        "##**Install Libs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqnpspqpbcIV",
        "outputId": "e8a3ce4a-49e7-498c-c6d8-e6b494bc0b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit==1.41.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gX27RPk8oH23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Setup Exposed env**"
      ],
      "metadata": {
        "id": "97RN9ylIoU73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG3k13yo2S4K",
        "outputId": "a21a25a4-15b3-4a0e-9da3-648e1c8aa15a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test-exposed-server.py\n"
          ]
        }
      ],
      "source": [
        "# Create simple streamlit project to test exposed env\n",
        "%%writefile test-exposed-server.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"My project\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First approach**  \n",
        "Using localTunnel: https://github.com/localtunnel/localtunnel"
      ],
      "metadata": {
        "id": "yiNu6sLKpGNC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LsBub0EfvtTy"
      },
      "outputs": [],
      "source": [
        "# Get localTunnel's password (Using wget or curl)\n",
        "!wget -q -O - https://loca.lt/mytunnelpassword\n",
        "# !curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxeNVvel2QHC"
      },
      "outputs": [],
      "source": [
        "# Run and expose streamlit port 8501\n",
        "!streamlit run test-exposed-server.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Second approach**  \n",
        "Using ngrok: https://ngrok.com/"
      ],
      "metadata": {
        "id": "XFgiPB6upW_-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMsXBx1KLlpW",
        "outputId": "a82978d7-6df3-4a22-c037-cd0d0af57689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0KAuthtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['NGROK_TOKEN'] = userdata.get('NGROK_TOKEN')\n",
        "\n",
        "# Authenticate ngrok with token getting from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "!npx ngrok config add-authtoken $NGROK_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run and expose streamlit port 8501\n",
        "!streamlit run test-exposed-server.py & npx ngrok http 8501 --log=stdout"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Rfj_yHq4ohOx",
        "outputId": "13ca8f70-58aa-4945-df41-8f16017360bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.245.135.162:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\u001b[32mINFO\u001b[0m[01-04|14:22:17] no configuration paths supplied \n",
            "\u001b[32mINFO\u001b[0m[01-04|14:22:17] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[01-04|14:22:17] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "t=2025-01-04T14:22:17+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2025-01-04T14:22:17+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2025-01-04T14:22:17+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2025-01-04T14:22:17+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:8501 url=https://c80d-35-245-135-162.ngrok-free.app\n",
            "t=2025-01-04T14:22:21+0000 lvl=info msg=\"join connections\" obj=join id=f251a7688f34 l=127.0.0.1:8501 r=115.75.32.98:64537\n",
            "t=2025-01-04T14:22:21+0000 lvl=info msg=\"join connections\" obj=join id=fc06e0eeae08 l=127.0.0.1:8501 r=115.75.32.98:64537\n",
            "t=2025-01-04T14:22:21+0000 lvl=info msg=\"join connections\" obj=join id=eed07bfb7878 l=127.0.0.1:8501 r=115.75.32.98:64537\n",
            "t=2025-01-04T14:22:21+0000 lvl=info msg=\"join connections\" obj=join id=0db9dfce4f85 l=127.0.0.1:8501 r=115.75.32.98:64537\n",
            "t=2025-01-04T14:22:21+0000 lvl=info msg=\"join connections\" obj=join id=68575bbda3f6 l=127.0.0.1:8501 r=115.75.32.98:64537\n",
            "t=2025-01-04T14:22:34+0000 lvl=info msg=\"join connections\" obj=join id=279bedd82b6d l=127.0.0.1:8501 r=115.75.32.98:64998\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "t=2025-01-04T14:23:53+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n",
            "t=2025-01-04T14:23:53+0000 lvl=info msg=\"session closing\" obj=tunnels.session err=nil\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIphK8ge2T0L"
      },
      "source": [
        "## **Basic**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykNL9LHm6yam",
        "outputId": "c2070356-1d57-4e6c-c2d1-985e679f6d2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Wusjqpr7xmSl5muHPkyBTpOCVtJI-avQ\n",
            "To: /content/Theme.jpeg\n",
            "\r  0% 0.00/161k [00:00<?, ?B/s]\r100% 161k/161k [00:00<00:00, 21.5MB/s]\n",
            "--2025-01-04 14:28:43--  https://picsum.photos/id/237/200/300\n",
            "Resolving picsum.photos (picsum.photos)... 104.26.4.30, 104.26.5.30, 172.67.74.163, ...\n",
            "Connecting to picsum.photos (picsum.photos)|104.26.4.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U [following]\n",
            "--2025-01-04 14:28:44--  https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U\n",
            "Resolving fastly.picsum.photos (fastly.picsum.photos)... 151.101.1.91, 151.101.65.91, 151.101.129.91, ...\n",
            "Connecting to fastly.picsum.photos (fastly.picsum.photos)|151.101.1.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10839 (11K) [image/jpeg]\n",
            "Saving to: ‘image.jpg’\n",
            "\n",
            "image.jpg           100%[===================>]  10.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-04 14:28:44 (68.2 MB/s) - ‘image.jpg’ saved [10839/10839]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download image\n",
        "!gdown 1Wusjqpr7xmSl5muHPkyBTpOCVtJI-avQ\n",
        "!wget -O image.jpg https://picsum.photos/id/237/200/300\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pVG-MH5zz6i",
        "outputId": "a768ecca-165e-4180-aa94-868ec3762fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit-components.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile streamlit-components.py\n",
        "import streamlit as st\n",
        "\n",
        "# Text elements\n",
        "st.title(\"MY PROJECT\")\n",
        "st.header(\"Header\")\n",
        "st.subheader(\"Subheader\")\n",
        "st.caption(\"Project for testing streamlit\")\n",
        "st.text(\"Testing element\")\n",
        "\n",
        "st.divider()\n",
        "# Markdown testing\n",
        "st.markdown(\"# Markdown section\")\n",
        "st.markdown(\"[Picsums](https://picsum.photos/)\")\n",
        "st.markdown(\"\"\"\n",
        "    1. Static Random Image\n",
        "    2. Grayscale Image\"\"\")\n",
        "st.markdown(r\"$\\sqrt{ax+by+c}$\")\n",
        "\n",
        "st.divider()\n",
        "# LaTeX testing\n",
        "st.markdown(\"# LaTeX 1\")\n",
        "st.latex(r\"\\sqrt{a^2+b^2}\")\n",
        "st.latex(r\"\\frac{m}{n} = k\")\n",
        "st.latex(r\"\\sqrt[3]{z} = w\")\n",
        "\n",
        "st.divider()\n",
        "# Code block with syntax highlighting\n",
        "st.markdown(\"# Code block\")\n",
        "st.code(\"\"\"\n",
        "    import torch\n",
        "    import os\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ['NGROK_TOKEN'] = userdata.get('NGROK_TOKEN')\n",
        "    data = torch.Tensor([1, 2, 3])\n",
        "    print(data)\n",
        "\"\"\", language=\"python\")\n",
        "\n",
        "st.divider()\n",
        "# Write Block\n",
        "st.markdown(\"# Write\")\n",
        "st.write('Normal text')\n",
        "st.write('## Write Block Heading')\n",
        "st.write(r'$ \\sqrt{2x+2} $')\n",
        "st.write('1 + 1 = ', 2)\n",
        "\n",
        "st.divider()\n",
        "# Echo Block\n",
        "st.markdown(\"# Echo Block\")\n",
        "st.caption(\"Display code block on app, and execute it\")\n",
        "\n",
        "def get_mail_domain():\n",
        "    return 'gmail.com'\n",
        "with st.echo():\n",
        "    st.write('Displaying code in echo block')\n",
        "    def get_user_name():\n",
        "        return 'asimpleman'\n",
        "    user_name = get_user_name()\n",
        "    mail_domain = get_mail_domain()\n",
        "    st.write(user_name,'@', mail_domain)\n",
        "\n",
        "st.divider()\n",
        "st.markdown(\"# Media block\")\n",
        "st.image(\n",
        "    './image.jpg',\n",
        "    caption='picsums'\n",
        ")\n",
        "# st.audio('./audio.mp4')\n",
        "# st.video('./video.mp4')\n",
        "\n",
        "st.divider()\n",
        "st.markdown(\"# Widgets block\")\n",
        "name = st.text_input(\"What's your name\", \"James Francis Ryan\")\n",
        "st.write(\"Your name is\", name)\n",
        "\n",
        "st.divider()\n",
        "\n",
        "def on_agree_terms():\n",
        "    st.write(\"Thank for agree on Terms and Conditions\")\n",
        "agree = st.checkbox(\"Agree on Terms and Conditions\", on_change=on_agree_terms)\n",
        "if agree:\n",
        "    st.write(\"Great!\")\n",
        "\n",
        "form_color = st.radio(\n",
        "    \"Your favorite color:\",\n",
        "    ['Yellow', 'Bleu'],\n",
        "    captions = ['Vàng', 'Xanh']\n",
        ")\n",
        "st.write('form_radio', form_color)\n",
        "\n",
        "form_contact = st.selectbox(\n",
        "    \"Your contact:\",\n",
        "    (\"Email\", \"Home phone\", \"Mobile phone\"))\n",
        "\n",
        "st.write(\"Selected:\", form_contact)\n",
        "\n",
        "form_colors = st.multiselect(\n",
        "    \"Your favorite colors:\",\n",
        "    [\"Green\", \"Yellow\", \"Red\", \"Blue\"],\n",
        "    [\"Yellow\", \"Red\"])\n",
        "\n",
        "st.write(\"You selected:\", form_colors)\n",
        "\n",
        "form_color_slider = st.select_slider(\n",
        "    \"Your favorite color:\",\n",
        "    options=[\"red\", \"orange\", \"violet\"])\n",
        "\n",
        "st.write(\"My favorite color is\", form_color_slider)\n",
        "\n",
        "if st.button(\"Say hello\"):\n",
        "    st.write(\"Hello\")\n",
        "else:\n",
        "    st.write(\"Goodbye\")\n",
        "\n",
        "st.link_button(\n",
        "    \"Go to Google\",\n",
        "    \"https://www.google.com.vn/\")\n",
        "\n",
        "number = st.number_input(\"Insert a number\")\n",
        "st.write(\"The current number is \", number)\n",
        "\n",
        "values = st.slider(\n",
        "    \"Select a range of values\",\n",
        "    0.0, 100.0, (25.0, 75.0))\n",
        "st.write(\"Values:\", values)\n",
        "\n",
        "\n",
        "st.divider()\n",
        "st.markdown(\"# Uploader\")\n",
        "form_upload_files = st.file_uploader(\n",
        "    \"Select files\", accept_multiple_files=True)\n",
        "\n",
        "for uploaded_file in form_upload_files:\n",
        "    bytes_data = uploaded_file.read()\n",
        "    st.write(\"filename:\", uploaded_file.name)\n",
        "\n",
        "\n",
        "st.divider()\n",
        "st.markdown(\"# Form batching\")\n",
        "st.caption(\"Create a form that batches elements together with a Submit button\")\n",
        "with st.form(\"information_form\"):\n",
        "    col1, col2 = st.columns(2)\n",
        "    f_name = col1.text_input('First Name')\n",
        "    l_name = col2.text_input('Last Name')\n",
        "    submitted = st.form_submit_button(\"Submit\")\n",
        "    if submitted:\n",
        "        st.write(\"First Name: \", f_name, \" - Last Name:\", l_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5c7W3aM3qgf",
        "outputId": "12560ae9-fced-4269-e984-90c4c1cc3b02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.245.135.162:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\u001b[32mINFO\u001b[0m[01-04|14:47:48] no configuration paths supplied \n",
            "\u001b[32mINFO\u001b[0m[01-04|14:47:48] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[01-04|14:47:48] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "t=2025-01-04T14:47:48+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2025-01-04T14:47:49+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2025-01-04T14:47:49+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2025-01-04T14:47:49+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:8501 url=https://09a2-35-245-135-162.ngrok-free.app\n",
            "t=2025-01-04T14:52:46+0000 lvl=info msg=\"join connections\" obj=join id=c9c2fce3abcd l=127.0.0.1:8501 r=115.75.32.98:59408\n",
            "t=2025-01-04T14:52:47+0000 lvl=info msg=\"join connections\" obj=join id=921d7f0d3f64 l=127.0.0.1:8501 r=115.75.32.98:59408\n",
            "t=2025-01-04T14:52:47+0000 lvl=info msg=\"join connections\" obj=join id=a5393663617b l=127.0.0.1:8501 r=115.75.32.98:59408\n",
            "t=2025-01-04T14:52:47+0000 lvl=info msg=\"join connections\" obj=join id=125aa10f024b l=127.0.0.1:8501 r=115.75.32.98:59408\n",
            "t=2025-01-04T14:52:47+0000 lvl=info msg=\"join connections\" obj=join id=aaad64ab7806 l=127.0.0.1:8501 r=115.75.32.98:59408\n",
            "t=2025-01-04T14:52:53+0000 lvl=info msg=\"join connections\" obj=join id=1d72a933acdd l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:53+0000 lvl=info msg=\"join connections\" obj=join id=16abdaf68021 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:53+0000 lvl=info msg=\"join connections\" obj=join id=967778ef4724 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:53+0000 lvl=info msg=\"join connections\" obj=join id=7ee2430bbfbc l=127.0.0.1:8501 r=115.75.32.98:59647\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=2c42dab04e44 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=ead2327dfc72 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=c6db719d8744 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=9aa5b6a56c03 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=463a4c6f96ae l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=aa7257c72b06 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=ca723ccfd15b l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=df244fa898dd l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=ff6bb32fc56d l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=c2ad8abaf1ca l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=91e9a285fc81 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=a3df6224e93c l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=daad8220f876 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=1b9b73ea1f81 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=0bf3ccdf78e1 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=e0ed80356764 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=5b495eaa2a2d l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=a7e223f00d7d l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:54+0000 lvl=info msg=\"join connections\" obj=join id=369dc10400f2 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:55+0000 lvl=info msg=\"join connections\" obj=join id=04ecb2a6fc82 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:55+0000 lvl=info msg=\"join connections\" obj=join id=c7b46fa34edc l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:55+0000 lvl=info msg=\"join connections\" obj=join id=6b40f72a1bc1 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:55+0000 lvl=info msg=\"join connections\" obj=join id=e5336af1e6b6 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:55+0000 lvl=info msg=\"join connections\" obj=join id=56435d5fe805 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:55+0000 lvl=info msg=\"join connections\" obj=join id=d83ba5dbb9f2 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:55+0000 lvl=info msg=\"join connections\" obj=join id=5a18b9f74364 l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:52:55+0000 lvl=info msg=\"join connections\" obj=join id=dd9a423883eb l=127.0.0.1:8501 r=115.75.32.98:59645\n",
            "t=2025-01-04T14:55:28+0000 lvl=info msg=\"join connections\" obj=join id=07f5e8a8bf20 l=127.0.0.1:8501 r=115.75.32.98:64790\n"
          ]
        }
      ],
      "source": [
        "!streamlit run streamlit-components.py & npx ngrok http 8501 --log=stdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICYb8Afa9Uy-"
      },
      "source": [
        "## **Applications**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__wI9ciEXklL"
      },
      "source": [
        "### **Sentiment Analysis using NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKynfjQLQUiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055502ae-d535-40cd-eaa9-e56fb730558f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sentiment_analysis.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile sentiment_analysis.py\n",
        "\n",
        "import streamlit as st\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def main():\n",
        "    st.title('Sentiment Analysis')\n",
        "    st.title('NLTK Library')\n",
        "    sentence = st.text_input(\"Sentence: \", \"This movie is bad.\")\n",
        "\n",
        "    sentiment_scores = sid.polarity_scores(sentence)\n",
        "    st.write(f'Sentiment Scores: ', sentiment_scores)\n",
        "\n",
        "    sentiment_scores = sorted(\n",
        "        sentiment_scores.items(),\n",
        "        key=lambda item: item[1],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    if sentiment_scores[0][0] == 'neg':\n",
        "        st.success(f'Sentiment: Negative')\n",
        "    else:\n",
        "        st.success(f'Sentiment: Positive')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "     main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnfB3TPnXqW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad791907-02a2-4158-cf8f-1bae19239297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.75.46.156:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\u001b[32mINFO\u001b[0m[01-03|16:33:00] no configuration paths supplied \n",
            "\u001b[32mINFO\u001b[0m[01-03|16:33:00] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[01-03|16:33:00] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "t=2025-01-03T16:33:00+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2025-01-03T16:33:00+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2025-01-03T16:33:00+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2025-01-03T16:33:00+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:8501 url=https://9946-34-75-46-156.ngrok-free.app\n",
            "t=2025-01-03T16:33:05+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n",
            "t=2025-01-03T16:33:21+0000 lvl=info msg=\"join connections\" obj=join id=ce881a94ba5c l=127.0.0.1:8501 r=123.21.251.160:53211\n",
            "t=2025-01-03T16:33:21+0000 lvl=info msg=\"join connections\" obj=join id=bf17ae255a31 l=127.0.0.1:8501 r=123.21.251.160:53211\n",
            "t=2025-01-03T16:33:21+0000 lvl=info msg=\"join connections\" obj=join id=1982c2e10000 l=127.0.0.1:8501 r=123.21.251.160:53211\n",
            "t=2025-01-03T16:33:21+0000 lvl=info msg=\"join connections\" obj=join id=6099cb64c5dd l=127.0.0.1:8501 r=123.21.251.160:53211\n",
            "t=2025-01-03T16:33:21+0000 lvl=info msg=\"join connections\" obj=join id=198a1f3573a3 l=127.0.0.1:8501 r=123.21.251.160:53211\n",
            "t=2025-01-03T16:33:24+0000 lvl=info msg=\"join connections\" obj=join id=1872714fb3f0 l=127.0.0.1:8501 r=123.21.251.160:53211\n",
            "t=2025-01-03T16:33:25+0000 lvl=info msg=\"join connections\" obj=join id=3d87c991a26c l=127.0.0.1:8501 r=123.21.251.160:53282\n",
            "t=2025-01-03T16:33:26+0000 lvl=info msg=\"join connections\" obj=join id=86e37c770e1c l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=ddaeba5d0fdb l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=a116cfeb226b l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=bf86f6b18447 l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=982d65a124ad l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=5b3d1dd7c587 l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=08be662c3822 l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=8ea067702b75 l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=47ff312e1b9c l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=8c5e5108547d l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=ec9b450f7863 l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "t=2025-01-03T16:37:59+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n",
            "t=2025-01-03T16:37:59+0000 lvl=info msg=\"session closing\" obj=tunnels.session err=nil\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run sentiment_analysis.py & npx ngrok http 8501 --log=stdout"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADhU39Si_RN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiGJngoDFXUq"
      },
      "source": [
        "### **Contextual Spell Correction using Spacy and contextualSpellCheck**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGsuWhA1X0uq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6cec83-e3e7-4139-e645-5c611a3bff32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.1/128.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/282.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.6/282.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q spacy contextualSpellCheck==0.4.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8zpCDr_EKQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b360c9c4-bacd-4f6e-920e-c9080899d883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting spell_corrector.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile spell_corrector.py\n",
        "import streamlit as st\n",
        "import spacy\n",
        "import contextualSpellCheck\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "contextualSpellCheck.add_to_pipe(nlp)\n",
        "\n",
        "def spell_corrector(sentence):\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    return doc._.performed_spellCheck, doc._.outcome_spellCheck\n",
        "\n",
        "def main():\n",
        "    st.title('Contextual Spell Correction')\n",
        "    st.title('Spacy + contextualSpellCheck')\n",
        "    sentence = st.text_input(\"Sentence: \", \"I go to slaep.\")\n",
        "    result = spell_corrector(sentence)\n",
        "    if result[0]:\n",
        "        st.success(f'Corrected: {result[1]}')\n",
        "    else:\n",
        "        st.success(f'Sentence: {sentence}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "     main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfxIh-GMX8f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eddb7da-7bce-4e78-bc0d-f5d40cf8400f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.75.46.156:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K\u001b[32mINFO\u001b[0m[01-03|16:39:08] no configuration paths supplied \n",
            "\u001b[32mINFO\u001b[0m[01-03|16:39:08] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[01-03|16:39:08] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "t=2025-01-03T16:39:08+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2025-01-03T16:39:08+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2025-01-03T16:39:08+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2025-01-03T16:39:08+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:8501 url=https://6107-34-75-46-156.ngrok-free.app\n",
            "t=2025-01-03T16:39:13+0000 lvl=info msg=\"join connections\" obj=join id=90dc35289e08 l=127.0.0.1:8501 r=123.21.251.160:63194\n",
            "t=2025-01-03T16:39:13+0000 lvl=info msg=\"join connections\" obj=join id=a2b9f8e3710f l=127.0.0.1:8501 r=123.21.251.160:63194\n",
            "t=2025-01-03T16:39:13+0000 lvl=info msg=\"join connections\" obj=join id=d54537b0e850 l=127.0.0.1:8501 r=123.21.251.160:63194\n",
            "t=2025-01-03T16:39:13+0000 lvl=info msg=\"join connections\" obj=join id=a85cab17a8e9 l=127.0.0.1:8501 r=123.21.251.160:63194\n",
            "t=2025-01-03T16:39:13+0000 lvl=info msg=\"join connections\" obj=join id=6df183196afa l=127.0.0.1:8501 r=123.21.251.160:63194\n",
            "t=2025-01-03T16:39:16+0000 lvl=info msg=\"join connections\" obj=join id=d17f2966f89a l=127.0.0.1:8501 r=123.21.251.160:63316\n",
            "tokenizer_config.json: 100% 49.0/49.0 [00:00<00:00, 243kB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 3.01MB/s]\n",
            "vocab.txt: 100% 213k/213k [00:00<00:00, 4.85MB/s]\n",
            "tokenizer.json: 100% 436k/436k [00:00<00:00, 18.8MB/s]\n",
            "2025-01-03 16:39:48.808769: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-03 16:39:48.866758: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-03 16:39:48.885831: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-03 16:39:48.935251: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-03 16:39:51.576984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "model.safetensors: 100% 436M/436M [00:02<00:00, 149MB/s]\n",
            "t=2025-01-03T16:39:58+0000 lvl=info msg=\"join connections\" obj=join id=c52470101a7c l=127.0.0.1:8501 r=123.21.251.160:64474\n",
            "t=2025-01-03T16:39:58+0000 lvl=info msg=\"join connections\" obj=join id=30a11ef7d1ca l=127.0.0.1:8501 r=123.21.251.160:64474\n",
            "t=2025-01-03T16:39:58+0000 lvl=info msg=\"join connections\" obj=join id=ab2268a241bf l=127.0.0.1:8501 r=123.21.251.160:64474\n",
            "2025-01-03 16:39:58.667 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "t=2025-01-03T16:39:59+0000 lvl=info msg=\"join connections\" obj=join id=d5b3f6bea1e0 l=127.0.0.1:8501 r=123.21.251.160:64474\n",
            "t=2025-01-03T16:40:49+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n",
            "t=2025-01-03T16:40:49+0000 lvl=info msg=\"session closing\" obj=tunnels.session err=nil\n",
            "t=2025-01-03T16:40:49+0000 lvl=info msg=\"accept failed\" obj=tunnels.session obj=csess id=d3ced7f38500 err=\"reconnecting session closed\"\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run spell_corrector.py & npx ngrok http 8501 --log=stdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M9EXKzGFOTa"
      },
      "source": [
        "### **English-Vietnamese Machine Translation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOR1GtkE9XHW"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.47.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L4-RrbX9vWI"
      },
      "outputs": [],
      "source": [
        "%%writefile en_vi_machine_translation.py\n",
        "import streamlit as st\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# download model\n",
        "model_name = \"thainq107/t5-small-en-vi\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "def translate(sentence, tokenizer, model):\n",
        "    tokenized_sentence = tokenizer.encode(\n",
        "        sentence, return_tensors=\"pt\").to(device)\n",
        "    output_ids = model.generate(tokenized_sentence, max_length=128)\n",
        "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    return output\n",
        "\n",
        "def main():\n",
        "    st.title('English-Vietnamese Machine Translation')\n",
        "    st.title('Model: T5. Dataset: En-Vi')\n",
        "    sentence = st.text_input(\"Sentence: \", \"I go to school.\")\n",
        "    result = translate(sentence, tokenizer, model)\n",
        "    st.success(f'Translated: {result}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "     main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1gW8jGg_uFh"
      },
      "outputs": [],
      "source": [
        "!streamlit run en_vi_machine_translation.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ICYb8Afa9Uy-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}