{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dattnguyen1991/aio_warmup_draft/blob/main/warmup/w3_Streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znxPoNGjvj-D"
      },
      "source": [
        "##**Install Libs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqnpspqpbcIV",
        "outputId": "6c899703-e860-4a30-a2d5-cdff1d685713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit==1.41.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsBub0EfvtTy",
        "outputId": "142cdfc5-ce3b-4cb5-9f8b-772f77d7143a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0KAuthtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K^C\n"
          ]
        }
      ],
      "source": [
        "!npx ngrok config add-authtoken 5BN44AQTHh2Sychn3XryC_833mxw7aJi2tbPkyvYs7e\n",
        "\n",
        "# get your password\n",
        "!wget -q -O - https://loca.lt/mytunnelpassword\n",
        "# !curl https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG3k13yo2S4K",
        "outputId": "d493b543-27dc-4e4e-dbf3-4388b72489c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demo.py\n"
          ]
        }
      ],
      "source": [
        "# prepare file demo.py\n",
        "%%writefile demo.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"MY PROJECT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxeNVvel2QHC",
        "outputId": "16e97c9a-459c-4974-f201-04e7914acffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20GUsage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
            "Try 'streamlit run --help' for help.\n",
            "\n",
            "Error: Invalid value: File does not exist: demo.py\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# run streamlit through port: 8501\n",
        "!streamlit run demo.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMsXBx1KLlpW",
        "outputId": "5e45883c-982e-4dd8-81bd-84f21be2d9a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.75.46.156:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K\u001b[32mINFO\u001b[0m[01-03|15:52:49] no configuration paths supplied \n",
            "\u001b[32mINFO\u001b[0m[01-03|15:52:49] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[01-03|15:52:49] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "t=2025-01-03T15:52:50+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2025-01-03T15:52:50+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2025-01-03T15:52:50+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2025-01-03T15:52:50+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:8501 url=https://39e3-34-75-46-156.ngrok-free.app\n",
            "t=2025-01-03T15:52:54+0000 lvl=info msg=\"join connections\" obj=join id=b24f5ce0e59a l=127.0.0.1:8501 r=123.21.251.160:65474\n",
            "t=2025-01-03T15:52:55+0000 lvl=info msg=\"join connections\" obj=join id=0790847da82e l=127.0.0.1:8501 r=123.21.251.160:65474\n",
            "t=2025-01-03T15:52:55+0000 lvl=info msg=\"join connections\" obj=join id=07f29d3b6764 l=127.0.0.1:8501 r=123.21.251.160:65474\n",
            "t=2025-01-03T15:52:55+0000 lvl=info msg=\"join connections\" obj=join id=8ebb41f6aa9d l=127.0.0.1:8501 r=123.21.251.160:65474\n",
            "t=2025-01-03T15:52:55+0000 lvl=info msg=\"join connections\" obj=join id=ce2df2a5af8f l=127.0.0.1:8501 r=123.21.251.160:65474\n",
            "t=2025-01-03T15:52:58+0000 lvl=info msg=\"join connections\" obj=join id=cdf01325e445 l=127.0.0.1:8501 r=123.21.251.160:49216\n",
            "t=2025-01-03T15:53:03+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n",
            "t=2025-01-03T15:53:03+0000 lvl=info msg=\"session closing\" obj=tunnels.session err=nil\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Using ngrok\n",
        "!streamlit run demo.py & npx ngrok http 8501 --log=stdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIphK8ge2T0L"
      },
      "source": [
        "## **Basic**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykNL9LHm6yam",
        "outputId": "ebbbcbce-b5c2-46c6-c102-ce4b1bdef6fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Wusjqpr7xmSl5muHPkyBTpOCVtJI-avQ\n",
            "To: /content/Theme.jpeg\n",
            "\r  0% 0.00/161k [00:00<?, ?B/s]\r100% 161k/161k [00:00<00:00, 86.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download image\n",
        "!gdown 1Wusjqpr7xmSl5muHPkyBTpOCVtJI-avQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pVG-MH5zz6i",
        "outputId": "c62b0627-ef92-4943-9ded-c37ba0b2b544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "# Text elements\n",
        "st.title(\"MY PROJECT\")\n",
        "st.header(\"This is a header\")\n",
        "st.subheader(\"This is a subheader\")\n",
        "st.caption(\"This is a caption\")\n",
        "st.text(\"I love AI VIET NAM\")\n",
        "\n",
        "# Displat string formatted as Markdown\n",
        "st.divider()\n",
        "\n",
        "st.markdown(\"# Heading 1\")\n",
        "st.markdown(\"[AI VIET NAM](https://aivietnam.edu.vn/)\")\n",
        "st.markdown(\"\"\"\n",
        "    1. Machine Learning\n",
        "    2. Deep Learning\"\"\")\n",
        "st.markdown(r\"$\\sqrt{2x+2}$\")\n",
        "\n",
        "# Display mathematical expressions formatted as LaTeX\n",
        "st.divider()\n",
        "\n",
        "st.latex(r\"\\sqrt{2x+2}\")\n",
        "\n",
        "# Display a code block with optional syntax highlighting\n",
        "st.divider()\n",
        "\n",
        "st.code(\"\"\"\n",
        "    import torch\n",
        "    data = torch.Tensor([1, 2, 3])\n",
        "    print(data)\n",
        "\"\"\", language=\"python\")\n",
        "\n",
        "# Write arguments to the app\n",
        "st.divider()\n",
        "\n",
        "st.write('I love AI VIET NAM')\n",
        "st.write('## Heading 2')\n",
        "st.write(r'$ \\sqrt{2x+2} $')\n",
        "st.write('1 + 1 = ', 2)\n",
        "\n",
        "# Echo: Use in a with block to draw some code on the app, then execute it\n",
        "st.divider()\n",
        "\n",
        "def get_user_name():\n",
        "    return 'Thai'\n",
        "with st.echo():\n",
        "    st.write('This code will be printed')\n",
        "    def get_email():\n",
        "        return 'thai@gmail.com'\n",
        "    user_name = get_user_name()\n",
        "    email = get_email()\n",
        "    st.write(user_name, email)\n",
        "\n",
        "# Media elements\n",
        "# Display an image/audio/video/logo\n",
        "st.divider()\n",
        "\n",
        "st.image(\n",
        "    './Theme.jpeg',\n",
        "    caption='Theme.'\n",
        ")\n",
        "# st.audio('./audio.mp4')\n",
        "# st.video('./video.mp4')\n",
        "\n",
        "# Input widgets\n",
        "st.divider()\n",
        "\n",
        "title = st.text_input(\"Movie title\", \"Life of Brian\")\n",
        "st.write(\"The current movie title is\", title)\n",
        "\n",
        "st.divider()\n",
        "\n",
        "def get_name():\n",
        "    st.write(\"Thai\")\n",
        "agree = st.checkbox(\"I agree\", on_change=get_name)\n",
        "if agree:\n",
        "    st.write(\"Great!\")\n",
        "\n",
        "st.radio(\n",
        "    \"Your favorite color:\",\n",
        "    ['Yellow', 'Bleu'],\n",
        "    captions = ['Vàng', 'Xanh']\n",
        ")\n",
        "\n",
        "option = st.selectbox(\n",
        "    \"Your contact:\",\n",
        "    (\"Email\", \"Home phone\", \"Mobile phone\"))\n",
        "\n",
        "st.write(\"Selected:\", option)\n",
        "\n",
        "options = st.multiselect(\n",
        "    \"Your favorite colors:\",\n",
        "    [\"Green\", \"Yellow\", \"Red\", \"Blue\"],\n",
        "    [\"Yellow\", \"Red\"])\n",
        "\n",
        "st.write(\"You selected:\", options)\n",
        "\n",
        "color = st.select_slider(\n",
        "    \"Your favorite color:\",\n",
        "    options=[\"red\", \"orange\", \"violet\"])\n",
        "st.write(\"My favorite color is\", color)\n",
        "\n",
        "if st.button(\"Say hello\"):\n",
        "    st.write(\"Hello\")\n",
        "else:\n",
        "    st.write(\"Goodbye\")\n",
        "\n",
        "st.link_button(\n",
        "    \"Go to Google\",\n",
        "    \"https://www.google.com.vn/\")\n",
        "\n",
        "number = st.number_input(\"Insert a number\")\n",
        "st.write(\"The current number is \", number)\n",
        "\n",
        "values = st.slider(\n",
        "    \"Select a range of values\",\n",
        "    0.0, 100.0, (25.0, 75.0))\n",
        "st.write(\"Values:\", values)\n",
        "\n",
        "# File uploader\n",
        "st.divider()\n",
        "\n",
        "uploaded_files = st.file_uploader(\n",
        "    \"Choose files\", accept_multiple_files=True)\n",
        "for uploaded_file in uploaded_files:\n",
        "    bytes_data = uploaded_file.read()\n",
        "    st.write(\"filename:\", uploaded_file.name)\\\n",
        "\n",
        "# Create a form that batches elements together with a \"Submit\" button\n",
        "st.divider()\n",
        "\n",
        "with st.form(\"my_form\"):\n",
        "    col1, col2 = st.columns(2)\n",
        "    f_name = col1.text_input('First Name')\n",
        "    l_name = col2.text_input('Last Name')\n",
        "    submitted = st.form_submit_button(\"Submit\")\n",
        "    if submitted:\n",
        "        st.write(\"First Name: \", f_name, \" - Last Name:\", l_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5c7W3aM3qgf",
        "outputId": "eb6c87a4-aed9-4ad2-8ce1-66ab2e2a48f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.75.46.156:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\u001b[32mINFO\u001b[0m[01-03|15:53:51] no configuration paths supplied \n",
            "\u001b[32mINFO\u001b[0m[01-03|15:53:51] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[01-03|15:53:51] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "t=2025-01-03T15:53:51+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2025-01-03T15:53:52+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2025-01-03T15:53:52+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2025-01-03T15:53:52+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:8501 url=https://bf0e-34-75-46-156.ngrok-free.app\n",
            "t=2025-01-03T15:53:59+0000 lvl=info msg=\"join connections\" obj=join id=8b9fc36359a4 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:00+0000 lvl=info msg=\"join connections\" obj=join id=8c2f459eb204 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:00+0000 lvl=info msg=\"join connections\" obj=join id=ebc85f67a10a l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:00+0000 lvl=info msg=\"join connections\" obj=join id=18b8176c0183 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:00+0000 lvl=info msg=\"join connections\" obj=join id=3e2b8e6072fc l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:03+0000 lvl=info msg=\"join connections\" obj=join id=43700e784629 l=127.0.0.1:8501 r=123.21.251.160:51056\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=c71a66a523ae l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=fb55762aa16c l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=6b7e53e30e8b l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=5a9a97ae11ac l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=053049904244 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=25066b53e875 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=07e2235a24c5 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=86f808fcde1a l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=0e07e3ba7c2b l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=8eab5836348b l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=6a901f5c3d9d l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=a20dcba4002d l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=272f583d8f7c l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=6fe276ee4d42 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=8f92d22da2b1 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=145afa288f6a l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=6bad67ab477c l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=b0311ef00b95 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:04+0000 lvl=info msg=\"join connections\" obj=join id=8bdf8b2eee65 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:05+0000 lvl=info msg=\"join connections\" obj=join id=3ebe6344f30a l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:05+0000 lvl=info msg=\"join connections\" obj=join id=535bf4775e4a l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:05+0000 lvl=info msg=\"join connections\" obj=join id=9dec117e28e4 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:05+0000 lvl=info msg=\"join connections\" obj=join id=0970d49c1b83 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:05+0000 lvl=info msg=\"join connections\" obj=join id=949a99b93bde l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:05+0000 lvl=info msg=\"join connections\" obj=join id=f0d37bdc3d4a l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:05+0000 lvl=info msg=\"join connections\" obj=join id=b692ab537f0b l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:54:05+0000 lvl=info msg=\"join connections\" obj=join id=d5351bafc7c9 l=127.0.0.1:8501 r=123.21.251.160:50934\n",
            "t=2025-01-03T15:58:33+0000 lvl=info msg=\"join connections\" obj=join id=5bcaf57a2ec0 l=127.0.0.1:8501 r=123.21.251.160:58806\n",
            "t=2025-01-03T16:11:02+0000 lvl=info msg=\"join connections\" obj=join id=e7c3ccb10c83 l=127.0.0.1:8501 r=123.21.251.160:63849\n",
            "t=2025-01-03T16:13:12+0000 lvl=info msg=\"join connections\" obj=join id=1b22df507489 l=127.0.0.1:8501 r=123.21.251.160:21267\n",
            "t=2025-01-03T16:14:12+0000 lvl=info msg=\"join connections\" obj=join id=c977c547f57c l=127.0.0.1:8501 r=123.21.251.160:52934\n",
            "t=2025-01-03T16:25:29+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n",
            "t=2025-01-03T16:25:29+0000 lvl=info msg=\"session closing\" obj=tunnels.session err=nil\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx ngrok http 8501 --log=stdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICYb8Afa9Uy-"
      },
      "source": [
        "## **Applications**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__wI9ciEXklL"
      },
      "source": [
        "### **Sentiment Analysis using NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKynfjQLQUiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055502ae-d535-40cd-eaa9-e56fb730558f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sentiment_analysis.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile sentiment_analysis.py\n",
        "\n",
        "import streamlit as st\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def main():\n",
        "    st.title('Sentiment Analysis')\n",
        "    st.title('NLTK Library')\n",
        "    sentence = st.text_input(\"Sentence: \", \"This movie is bad.\")\n",
        "\n",
        "    sentiment_scores = sid.polarity_scores(sentence)\n",
        "    st.write(f'Sentiment Scores: ', sentiment_scores)\n",
        "\n",
        "    sentiment_scores = sorted(\n",
        "        sentiment_scores.items(),\n",
        "        key=lambda item: item[1],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    if sentiment_scores[0][0] == 'neg':\n",
        "        st.success(f'Sentiment: Negative')\n",
        "    else:\n",
        "        st.success(f'Sentiment: Positive')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "     main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnfB3TPnXqW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad791907-02a2-4158-cf8f-1bae19239297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.75.46.156:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\u001b[32mINFO\u001b[0m[01-03|16:33:00] no configuration paths supplied \n",
            "\u001b[32mINFO\u001b[0m[01-03|16:33:00] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[01-03|16:33:00] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "t=2025-01-03T16:33:00+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2025-01-03T16:33:00+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2025-01-03T16:33:00+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2025-01-03T16:33:00+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:8501 url=https://9946-34-75-46-156.ngrok-free.app\n",
            "t=2025-01-03T16:33:05+0000 lvl=warn msg=\"failed to check for update\" obj=updater err=\"Post \\\"https://update.equinox.io/check\\\": context deadline exceeded\"\n",
            "t=2025-01-03T16:33:21+0000 lvl=info msg=\"join connections\" obj=join id=ce881a94ba5c l=127.0.0.1:8501 r=123.21.251.160:53211\n",
            "t=2025-01-03T16:33:21+0000 lvl=info msg=\"join connections\" obj=join id=bf17ae255a31 l=127.0.0.1:8501 r=123.21.251.160:53211\n",
            "t=2025-01-03T16:33:21+0000 lvl=info msg=\"join connections\" obj=join id=1982c2e10000 l=127.0.0.1:8501 r=123.21.251.160:53211\n",
            "t=2025-01-03T16:33:21+0000 lvl=info msg=\"join connections\" obj=join id=6099cb64c5dd l=127.0.0.1:8501 r=123.21.251.160:53211\n",
            "t=2025-01-03T16:33:21+0000 lvl=info msg=\"join connections\" obj=join id=198a1f3573a3 l=127.0.0.1:8501 r=123.21.251.160:53211\n",
            "t=2025-01-03T16:33:24+0000 lvl=info msg=\"join connections\" obj=join id=1872714fb3f0 l=127.0.0.1:8501 r=123.21.251.160:53211\n",
            "t=2025-01-03T16:33:25+0000 lvl=info msg=\"join connections\" obj=join id=3d87c991a26c l=127.0.0.1:8501 r=123.21.251.160:53282\n",
            "t=2025-01-03T16:33:26+0000 lvl=info msg=\"join connections\" obj=join id=86e37c770e1c l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=ddaeba5d0fdb l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=a116cfeb226b l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=bf86f6b18447 l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=982d65a124ad l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=5b3d1dd7c587 l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=08be662c3822 l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=8ea067702b75 l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=47ff312e1b9c l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=8c5e5108547d l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "t=2025-01-03T16:33:28+0000 lvl=info msg=\"join connections\" obj=join id=ec9b450f7863 l=127.0.0.1:8501 r=123.21.251.160:21612\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "t=2025-01-03T16:37:59+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n",
            "t=2025-01-03T16:37:59+0000 lvl=info msg=\"session closing\" obj=tunnels.session err=nil\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run sentiment_analysis.py & npx ngrok http 8501 --log=stdout"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ADhU39Si_RN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiGJngoDFXUq"
      },
      "source": [
        "### **Contextual Spell Correction using Spacy and contextualSpellCheck**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGsuWhA1X0uq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6cec83-e3e7-4139-e645-5c611a3bff32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.1/128.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/282.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.6/282.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q spacy contextualSpellCheck==0.4.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8zpCDr_EKQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b360c9c4-bacd-4f6e-920e-c9080899d883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting spell_corrector.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile spell_corrector.py\n",
        "import streamlit as st\n",
        "import spacy\n",
        "import contextualSpellCheck\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "contextualSpellCheck.add_to_pipe(nlp)\n",
        "\n",
        "def spell_corrector(sentence):\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    return doc._.performed_spellCheck, doc._.outcome_spellCheck\n",
        "\n",
        "def main():\n",
        "    st.title('Contextual Spell Correction')\n",
        "    st.title('Spacy + contextualSpellCheck')\n",
        "    sentence = st.text_input(\"Sentence: \", \"I go to slaep.\")\n",
        "    result = spell_corrector(sentence)\n",
        "    if result[0]:\n",
        "        st.success(f'Corrected: {result[1]}')\n",
        "    else:\n",
        "        st.success(f'Sentence: {sentence}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "     main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfxIh-GMX8f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eddb7da-7bce-4e78-bc0d-f5d40cf8400f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.75.46.156:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K\u001b[32mINFO\u001b[0m[01-03|16:39:08] no configuration paths supplied \n",
            "\u001b[32mINFO\u001b[0m[01-03|16:39:08] using configuration at default config path \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml\n",
            "\u001b[32mINFO\u001b[0m[01-03|16:39:08] open config file                         \u001b[32mpath\u001b[0m=/root/.config/ngrok/ngrok.yml \u001b[32merr\u001b[0m=nil\n",
            "t=2025-01-03T16:39:08+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4040 allow_hosts=[]\n",
            "t=2025-01-03T16:39:08+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2025-01-03T16:39:08+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2025-01-03T16:39:08+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:8501 url=https://6107-34-75-46-156.ngrok-free.app\n",
            "t=2025-01-03T16:39:13+0000 lvl=info msg=\"join connections\" obj=join id=90dc35289e08 l=127.0.0.1:8501 r=123.21.251.160:63194\n",
            "t=2025-01-03T16:39:13+0000 lvl=info msg=\"join connections\" obj=join id=a2b9f8e3710f l=127.0.0.1:8501 r=123.21.251.160:63194\n",
            "t=2025-01-03T16:39:13+0000 lvl=info msg=\"join connections\" obj=join id=d54537b0e850 l=127.0.0.1:8501 r=123.21.251.160:63194\n",
            "t=2025-01-03T16:39:13+0000 lvl=info msg=\"join connections\" obj=join id=a85cab17a8e9 l=127.0.0.1:8501 r=123.21.251.160:63194\n",
            "t=2025-01-03T16:39:13+0000 lvl=info msg=\"join connections\" obj=join id=6df183196afa l=127.0.0.1:8501 r=123.21.251.160:63194\n",
            "t=2025-01-03T16:39:16+0000 lvl=info msg=\"join connections\" obj=join id=d17f2966f89a l=127.0.0.1:8501 r=123.21.251.160:63316\n",
            "tokenizer_config.json: 100% 49.0/49.0 [00:00<00:00, 243kB/s]\n",
            "config.json: 100% 570/570 [00:00<00:00, 3.01MB/s]\n",
            "vocab.txt: 100% 213k/213k [00:00<00:00, 4.85MB/s]\n",
            "tokenizer.json: 100% 436k/436k [00:00<00:00, 18.8MB/s]\n",
            "2025-01-03 16:39:48.808769: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-03 16:39:48.866758: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-03 16:39:48.885831: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-03 16:39:48.935251: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-03 16:39:51.576984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "model.safetensors: 100% 436M/436M [00:02<00:00, 149MB/s]\n",
            "t=2025-01-03T16:39:58+0000 lvl=info msg=\"join connections\" obj=join id=c52470101a7c l=127.0.0.1:8501 r=123.21.251.160:64474\n",
            "t=2025-01-03T16:39:58+0000 lvl=info msg=\"join connections\" obj=join id=30a11ef7d1ca l=127.0.0.1:8501 r=123.21.251.160:64474\n",
            "t=2025-01-03T16:39:58+0000 lvl=info msg=\"join connections\" obj=join id=ab2268a241bf l=127.0.0.1:8501 r=123.21.251.160:64474\n",
            "2025-01-03 16:39:58.667 Examining the path of torch.classes raised: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "t=2025-01-03T16:39:59+0000 lvl=info msg=\"join connections\" obj=join id=d5b3f6bea1e0 l=127.0.0.1:8501 r=123.21.251.160:64474\n",
            "t=2025-01-03T16:40:49+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n",
            "t=2025-01-03T16:40:49+0000 lvl=info msg=\"session closing\" obj=tunnels.session err=nil\n",
            "t=2025-01-03T16:40:49+0000 lvl=info msg=\"accept failed\" obj=tunnels.session obj=csess id=d3ced7f38500 err=\"reconnecting session closed\"\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run spell_corrector.py & npx ngrok http 8501 --log=stdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M9EXKzGFOTa"
      },
      "source": [
        "### **English-Vietnamese Machine Translation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOR1GtkE9XHW"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.47.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L4-RrbX9vWI"
      },
      "outputs": [],
      "source": [
        "%%writefile en_vi_machine_translation.py\n",
        "import streamlit as st\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# download model\n",
        "model_name = \"thainq107/t5-small-en-vi\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "def translate(sentence, tokenizer, model):\n",
        "    tokenized_sentence = tokenizer.encode(\n",
        "        sentence, return_tensors=\"pt\").to(device)\n",
        "    output_ids = model.generate(tokenized_sentence, max_length=128)\n",
        "    output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    return output\n",
        "\n",
        "def main():\n",
        "    st.title('English-Vietnamese Machine Translation')\n",
        "    st.title('Model: T5. Dataset: En-Vi')\n",
        "    sentence = st.text_input(\"Sentence: \", \"I go to school.\")\n",
        "    result = translate(sentence, tokenizer, model)\n",
        "    st.success(f'Translated: {result}')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "     main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1gW8jGg_uFh"
      },
      "outputs": [],
      "source": [
        "!streamlit run en_vi_machine_translation.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}